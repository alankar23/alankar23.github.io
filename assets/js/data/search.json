[ { "title": "Kubernetes Disaster Recovery: Guide to etcd Backup", "url": "/posts/etcd-backup/", "categories": "", "tags": "linux, docker, kubernetes", "date": "2024-11-15 00:00:00 +0000", "snippet": "Kubernetes Etcd BackupEver wondered what happens when your Kubernetes cluster has a bad day? Let‚Äôs talk about backing up one of its most critical components - etcd, your cluster‚Äôs ‚Äúsource of truth.‚ÄùIntroductionKubernetes (K8s) is like a conductor orchestrating a complex symphony of containers. Behind this orchestration lies etcd, a distributed key-value store that maintains the entire state of your cluster. Think of etcd as Kubernetes‚Äô memory bank - it stores everything from your pod configurations to your secrets. Lose etcd, and you‚Äôre essentially losing your cluster‚Äôs brain!PrerequisitesBefore we dive into the backup process, make sure you have: Kubernetes cluster (well duh) Docker installed on your backup system Access to the Kubernetes control plane (master node) A cup Multiple cups of chai (optional but recommended ‚òï)Pro tip: While these are the minimum requirements, it‚Äôs always good practice to test your backup strategy on a development cluster first.Understanding etcdAuthentication: The Certificates You‚Äôll NeedSecurity first! To interact with etcd, you‚Äôll need these certificates: /etc/kubernetes/pki/etcd/ca.crt: The etcd CA certificate /etc/kubernetes/pki/etcd/server.crt: Server certificate /etc/kubernetes/pki/etcd/server.key: Server keyThese certs are your pass to etcd. Without them, you‚Äôre not getting in!üí° Extra Tips Worth Knowing: Store your backup certificates separately from your cluster Regular backup testing is as important as the backup itself Consider using automated backup solutions for production environments Keep track of your etcd version - it matters for restore operationsRemember: A backup is only as good as its latest test restore!How to Back Up etcdCluster etcd InformationTo back up etcd, you‚Äôll need the etcd version and the necessary certificates. Start by retrieving the details of your etcd pod:$ kubectl describe pods -n kube-system etcd-k8s-masterName: etcd-k8s-master Namespace: kube-system Priority: 2000001000 Priority Class Name: system-node-criticalNode: k8s-master/192.168.100.10Start Time: Fri, 01 Nov 2024 01:38:00 +0530 Labels: component=etcd tier=control-plane Annotations: kubeadm.kubernetes.io/etcd.advertise-client-urls: https://192.168.100.10:2379 kubernetes.io/config.hash: 0a0430dc440a1ab0ac89aac4cefec68c kubernetes.io/config.mirror: 0a0430dc440a1ab0ac89aac4cefec68c kubernetes.io/config.seen: 2024-09-07T10:46:31.843036711+05:30 kubernetes.io/config.source: file Status: Running IP: 192.168.100.10 IPs: IP: 192.168.100.10 Controlled By: Node/k8s-masterContainers: etcd: Container ID: containerd://2e02f2cbadcd4084acbd34374d397a94df6bfe0af9e4c8532e741320880e0b6d Image: registry.k8s.io/etcd:3.5.12-0 Image ID: registry.k8s.io/etcd@sha256:44a8e24dcbba3470ee1fee21d5e88d128c936e9b55d4bc51fbef8086f8ed123b Port: &lt;none&gt; Host Port: &lt;none&gt; Command: etcd --advertise-client-urls=https://192.168.100.10:2379 --cert-file=/etc/kubernetes/pki/etcd/server.crt --client-cert-auth=true --data-dir=/var/lib/etcd --experimental-initial-corrupt-check=true --experimental-watch-progress-notify-interval=5s --initial-advertise-peer-urls=https://192.168.100.10:2380 --initial-cluster=k8s-master=https://192.168.100.10:2380 --key-file=/etc/kubernetes/pki/etcd/server.key --listen-client-urls=https://127.0.0.1:2379,https://192.168.100.10:2379 --listen-metrics-urls=http://127.0.0.1:2381 --listen-peer-urls=https://192.168.100.10:2380 --name=k8s-master --peer-cert-file=/etc/kubernetes/pki/etcd/peer.crt --peer-client-cert-auth=true --peer-key-file=/etc/kubernetes/pki/etcd/peer.key --peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt --snapshot-count=10000 --trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt Mounts: /etc/kubernetes/pki/etcd from etcd-certs (rw) /var/lib/etcd from etcd-data (rw)Volumes: etcd-certs: Type: HostPath (bare host directory volume) Path: /etc/kubernetes/pki/etcd HostPathType: DirectoryOrCreate etcd-data: Type: HostPath (bare host directory volume) Path: /var/lib/etcd HostPathType: DirectoryOrCreateetcd Version:The etcd version can be found in the image tag of the pod:Image:registry.k8s.io/etcd:3.5.12-0 ### Certificates: Ensure you have the correct certificate paths to access etcd securely:--cert-file=/etc/kubernetes/pki/etcd/server.crt--key-file=/etc/kubernetes/pki/etcd/server.key --trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt ### Certificate Host Location:The certificate files are mounted from the host to the pod, as seen in the Volumes sectionVolumes: etcd-certs: Type: HostPath (bare host directory volume) Path: /etc/kubernetes/pki/etcd HostPathType: DirectoryOrCreatePrepTo start, we need to copy the certificates from the master node‚Äôs directory /etc/kubernetes/pki/etcd/ to your local machine‚Äôs etcd/certs directory for authentication with etcd.Example of the file structure in the etcd/certs directory:$ ls -l etcd/certs-rwxrwxrwx 1 user user 1 KiB Sun Nov 3 14:49:02 2024 ca.crt-rwxrwxrwx 1 user user 1 KiB Sun Nov 3 14:49:02 2024 server.crt-rwxrwxrwx 1 user user 1 KiB Sun Nov 3 14:49:02 2024 server.keyNext, we‚Äôll use Docker to run the etcd container, and set up a cron job to regularly execute the container and capture a snapshot of the etcd data.DockerfileWhy Run etcd in a Docker Container?Running the etcd backup container in Docker offers flexibility for future upgrades. If we decide to upgrade our cluster (including etcd) to a newer version, we‚Äôll also need to upgrade the etcd backup system. Instead of manually managing version updates, we can simply update the image tag in our Docker Compose file, making the process much easier.Our Dockerfileservices: etcd: image: bitnami/etcd:3.5.12 environment: ETCDCTL_API: 3 entrypoint: [\"etcdctl\",\"--endpoints\", \"https://192.168.100.10:2379\", \"--cacert=/certs/ca.crt\", \"--cert=/certs/server.crt\", \"--key=/certs/server.key\", \"snapshot\", \"save\", \"/backup/snapshot.db\"] volumes: - ./etcd/certs:/certs - ./backup:/backupIn this setup, we‚Äôve mounted the necessary certificates and the backup directory into the container. We use the etcdctl snapshot save command to create the snapshot backup.Running the ContainerWhen we run the container using Docker Compose, we should see the following output:$ docker compose up [+] Running 2/0 ‚†ø Network etcd-backup_default Created 0.0s ‚†ø Container etcd-backup-etcd-1 Created 0.0sAttaching to etcd-backup-etcd-1etcd-backup-etcd-1 | {\"level\":\"info\",\"ts\":\"2024-11-15T08:19:48.879484Z\",\"caller\":\"snapshot/v3_snapshot.go:65\",\"msg\":\"created temporary db file\",\"path\":\"/backup/snapshot.db.part\"}etcd-backup-etcd-1 | {\"level\":\"info\",\"ts\":\"2024-11-15T08:19:49.029314Z\",\"logger\":\"client\",\"caller\":\"v3@v3.5.12/maintenance.go:212\",\"msg\":\"opened snapshot stream; downloading\"}etcd-backup-etcd-1 | {\"level\":\"info\",\"ts\":\"2024-11-15T08:19:49.029366Z\",\"caller\":\"snapshot/v3_snapshot.go:73\",\"msg\":\"fetching snapshot\",\"endpoint\":\"https://192.168.100.10:2379\"}etcd-backup-etcd-1 | {\"level\":\"info\",\"ts\":\"2024-11-15T08:20:13.297681Z\",\"logger\":\"client\",\"caller\":\"v3@v3.5.12/maintenance.go:220\",\"msg\":\"completed snapshot read; closing\"}etcd-backup-etcd-1 | {\"level\":\"info\",\"ts\":\"2024-11-15T08:20:13.355176Z\",\"caller\":\"snapshot/v3_snapshot.go:88\",\"msg\":\"fetched snapshot\",\"endpoint\":\"https://192.168.100.10:2379\",\"size\":\"49 MB\",\"took\":\"24 seconds ago\"}etcd-backup-etcd-1 | {\"level\":\"info\",\"ts\":\"2024-11-15T08:20:13.355275Z\",\"caller\":\"snapshot/v3_snapshot.go:97\",\"msg\":\"saved\",\"path\":\"/backup/snapshot.db\"}etcd-backup-etcd-1 | Snapshot saved at /backup/snapshot.dbAnd voil√†! Our etcd backup container is now up and running, successfully saving the snapshot.Automating the BackupShell ScriptCreate the backup shell script (etcd.sh), which will run the Docker Compose command and compress each snapshot file with a date and time stamp to reduce its size:$ cat etcd.sh#!/bin/bash# Change this to your project directorycd /home/alankar/etcd-backupdocker compose up # Define source and destination directoriesSOURCE_DIR=\"backup/snapshot.db\"DEST_alankar=\"backup\" # Get the current time for the zip file name and today's date for the directory nameCURRENT_TIME=$(date +\"%H-%M\")TODAY_DATE=$(date +\"%d-%m\")# Define the zip file name and the destination directory pathZIP_NAME=\"etcd-$CURRENT_TIME.zip\"DEST_DIR=\"$DEST_alankar/$TODAY_DATE\"# Create the destination directory if it doesn't existmkdir -p \"$DEST_DIR\"# Create the zip filezip -r \"$DEST_DIR/$ZIP_NAME\" \"$SOURCE_DIR\"# Output the resultecho \"Created zip file: $DEST_DIR/$ZIP_NAME\"Basically this script runs the Docker Compose backup and then compresses the resulting snapshot file, saving it with a timestamp to help organize backups.CrontabWe‚Äôll now schedule this script to run every 12 hours using crontab. This way, backups will be taken automatically without manual intervention.$ crontab -l0 */12 * * * /home/alankar/etcd-backup/etcd.sh &gt;/home/alankar/etcd-backup/etcd.log We are running our script at every 12 th our of the day and spitting the output in etcd.logChecking the Backup OutputYou can check the log file (etcd.log) to see the backup process in action:$ cat etcd.log Run Time is 12-00Attaching to etcd-etcd-1etcd-etcd-1 | Snapshot saved at /backup/snapshot.dbetcd-etcd-1 exited with code 0 adding: backup/snapshot.db (deflated 69%)Created zip file: backup/15-11/etcd-12-00.zipYou can also verify the backups in the backup directory:$ ls -l backup/drwxr-xr-x 2 alankar alankar 4096 Nov 15 12:00 15-11-rw------- 1 alankar alankar 48611360 Nov 15 12:00 snapshot.db$ ls -l backup/15-11/total 29024-rw-r--r-- 1 alankar alankar 14872336 Nov 15 00:00 etcd-00-00.zip-rw-r--r-- 1 alankar alankar 14847133 Nov 15 12:00 etcd-12-00.zipRestoring etcdTo restore an etcd snapshot: Extract the Snapshot:Decompress the zip file to retrieve the snapshot.db. Use the Compose File:In the restore folder, you‚Äôll find a member directory, which you‚Äôll need to copy to your master node. services: etcd: image: bitnami/etcd:3.5.12 environment: ETCDCTL_API: 3 entrypoint: [\"etcdctl\",\"--data-dir\", \"/restore/\", \"snapshot\",\"restore\", \"/backup/snapshot.db\"] volumes: - ./backup:/backup - ./restore:/restore $ ls restore/ member Copy the member directory to your master nod. Update the etcd.yaml Static Pod: Copy the member directory to your master node and edit the etcd.yaml static pod at /etc/kubernetes/manifests Change this path to - hostPath: path: /var/lib/etcd type: DirectoryOrCreate name: etcd-data To this: volumes: - hostPath: path: /var/new/etcd type: DirectoryOrCreate name: etcd-data Wait for the Changes to Reflect: After editing the static pod file, wait a few minutes for the changes to take effect. Your etcd will now be restored from the snapshot. " }, { "title": "Welcome to my blog!", "url": "/posts/wellcome/", "categories": "", "tags": "", "date": "2022-06-22 00:00:00 +0000", "snippet": "‚ÄúEmbarking on a Journey into the World of Tech: Unveiling the Marvels of Microservices, Cloud Magic, and Linux Love!Welcome to my inaugural blog post, where the tech odyssey begins! Join me as I dive headfirst into the captivating realms of:üöÄ Mastering Microservices: Crafting the Future of Developmentüåê Unleashing Microservices: From Deployment to Dominanceüì¶ Containers: Unveiling the Secrets of Seamless Software Shipping‚òÅÔ∏è Navigating Kubernetes: The Captain of Cloud Orchestration‚öôÔ∏è Embracing DevOps: Where Collaboration Meets Innovation‚ú® Best Practices: Illuminating the Path to Tech Excellenceüí° Cloud Chronicles: Tips and Tricks for Conquering Infrastructure Managementüåü Open Source Wonders: Celebrating the Heartbeat of Softwareüêß GNU/Linux Love: Embracing the Elegance of My Favorite Operating SystemBuckle up buckaroos as we explore, learn, and celebrate the dynamic universe of technology together. Your gateway to tech brilliance has arrived ‚Äì let‚Äôs dive in with gusto! üéâüî•" }, { "title": "Static ip for Linux ", "url": "/posts/set-static-ip/", "categories": "", "tags": "linux, networking", "date": "2022-06-22 00:00:00 +0000", "snippet": "Configuring a Static IP Address for Your Linux MachineTo ensure a seamless setup of a static IP for your Linux machine, it‚Äôs imperative to have root privileges. This privilege level is essential for establishing a static IP effectively. Assuming you possess the necessary superuser privileges, let‚Äôs delve into the process.Navigate to the ‚Äònetplan‚Äô DirectoryCommence by accessing the ‚Äònetplan‚Äô directory. This can be accomplished by executing the following commandcd etc/netplanWithin the etc/netplan directory, a file named something like 00-netplan awaits your attention. In case this file is absent, you should create one. Subsequently, insert the code block provided below into this file.# This is the network config written by Alankarnetwork:ethernets: ens3: addresses: - 192.168.1.10/24 gateway4: 192.168.1.254 nameservers: addresses: - 8.8.8.8 - 8.8.4.4version: 2Understanding the ConfigurationLet‚Äôs decipher the significance of each line within the configuration:Static IP Address Assignment:addresses:- 192.168.1.10/24In this segment, the address ‚Äú192.168.1.10‚Äù signifies the desired static IP address for the machine. It‚Äôs crucial to append ‚Äú/24‚Äù at the end.Network Gateway Specification:gateway4: 192.168.1.254This value corresponds to the network gateway or router IP. Identifying this can be achieved by executing the command:$ ip r | grep defaultdefault via 192.168.1.254 dev wlp8s0 proto dhcp metric 600so, 192.168.1.254 is my router ip / gateway ip in my context..DNS Server Configuration:nameservers: addresses: - 8.8.8.8 - 8.8.4.4This section contains the DNS records. My preference is Google‚Äôs DNS, namely 8.8.8.8 and 8.8.4.4. Alternatively, you can opt for Cloudflare‚Äôs DNS or any custom DNS of your choice.Applying Changes:To implement the configured changes, execute the subsequent commands:$ sudo netplan generate$ sudo netplan applyFinalizing the Process:Following the implementation of changes, a system reboot is necessary for the alterations to take effect. Once this step is concluded, you can ascertain the success of the operation by executing either of the following commandsip rorhostname -IThe output should resemble:192.168.1.10 This confirms the successful assignment of the specified static IP to your Linux machine." } ]
